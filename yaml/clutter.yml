logging_directory: "/tmp/robamine_logs"
mode: Train  # Options: "Train", "Evaluate", "Train & Evaluate", "Random"
train:
  episodes: 6000
  render: False
eval:
  episodes: 10
  render: False
eval_every: 1000
save_every: 10
load_world: ""  # Path to load world. Empty string means new world
env:
  name: 'Clutter-v0'
  discrete: True
  nr_of_actions: 8
  render: False
  nr_of_obstacles: [5, 8]
  target_probability_box: 1.0
  obstacle_probability_box: 1.0
  push_distance: 0.1
  split: False
agent:
  name: 'DQN'
  replay_buffer_size: 1000000
  batch_size: 32
  discount: 0.9
  target_net_updates: 1000
  tau: 0.999
  double_dqn: False
  epsilon_start: 0.9
  epsilon_end: 0.05
  epsilon_decay: 20000  # number of learning steps for half epsilon, set to 0 if no decay is needed
  learning_rate: 0.001
  hidden_units: [140, 140]
  device: 'cpu'  # "cuda", "cpu"

