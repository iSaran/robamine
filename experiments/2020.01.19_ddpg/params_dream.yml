agent:
  name: SplitDDPG
  params:
    actions: [3]
    batch_size: [64, 64]
    device: cpu
    gamma: 0.99
    load_buffers: ''
    load_nets: ''
    replay_buffer_size: 1000000
    tau: 0.001
    update_iter: [1, 1]
    actor:
      hidden_units: [[400, 300], [400, 300]]
      learning_rate: 0.001
    critic:
      hidden_units: [[400, 300], [400, 300]]
      learning_rate: 0.001
    noise:
      name: Normal
      sigma: 0.2
    epsilon:
      start: 0.9
      end: 0.05
      decay: 10000
    heightmap_rotations: 8
    # load_actors:  # Uncomment to use pretrained actors. Comment-out for initialize actors from scratch it if want to initialize actors from scratch
    #   - /home/iason/Dropbox/projects/phd/clutter/training/2020.01.16.split_ddpg/robamine_logs_2020.02.05.15.20.58.472410_bck/model.pkl
    #   - /home/iason/Dropbox/projects/phd/clutter/training/2020.01.16.split_ddpg/robamine_logs_2020.02.05.15.20.58.472410_bck/model.pkl
    n_preloaded_buffer: [1000, 1000]
  trainable_params: ''
env:
  name: ClutterContWrapper-v0
  params:
    all_equal_height_prob: 0.0
    finger_size:
    - 0.005
    - 0.005
    nr_of_obstacles:
    - 1
    - 8
    render: false
    target:
      min_bounding_box: [.01, .01, .005]
      max_bounding_box: [.03, .03, .010]
      probability_box: 1.0
      enforce_convex_hull: 15
    obstacle:
      min_bounding_box: [.01, .01, .005]
      max_bounding_box: [.03, .03, .020]
      probability_box: 1.0
    push:
      distance: [0.02, 0.10]
      target_init_distance: [0.0, 0.1]
    grasp:
      spread: [0.05, 0.05]
      height: [0.01, 0.01]
      workspace: [0.0, 0.1]
    feature_normalization_per: 'session'  # available: 'session', 'episode'
    heightmap_rotations: 8
    max_timesteps: 20
    log_dir: /home/espa/robamine_logs/test
env_eval:
  name: ClutterCont-v0
  params:
    all_equal_height_prob: 0.0
    finger_size:
    - 0.005
    - 0.005
    nr_of_obstacles:
    - 6
    - 8
    render: false
    target:
      min_bounding_box: [.01, .01, .005]
      max_bounding_box: [.03, .03, .010]
      probability_box: 1.0
      enforce_convex_hull: 15
    obstacle:
      min_bounding_box: [.01, .01, .005]
      max_bounding_box: [.03, .03, .020]
      probability_box: 1.0
    push:
      distance: [0.02, 0.10]
      target_init_distance: [0.0, 0.1]
    grasp:
      spread: [0.05, 0.05]
      height: [0.01, 0.01]
      workspace: [0.0, 0.1]
    feature_normalization_per: 'session'  # available: 'session', 'episode'
    heightmap_rotations: 8
    max_timesteps: 5
world:
  comments: ''
  friendly_name: ''
  logging_dir: /home/espa/robamine_logs
  name: TrainEval
  params:
    episodes: 5000
    eval_episodes: 10
    eval_every: 20
    eval_render: false
    render: false
    save_every: 200
